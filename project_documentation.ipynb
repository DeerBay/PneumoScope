{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pneumonia Detection from X-rays**\n",
    "## Project Documentation\n",
    "#### Authors: [Sebastian Fredin, Ali Hussain, Julia Sjöholm, Younis Moussavi]\n",
    "#### Course: Deep-Learning, AI23 IT-Högskolan Göteborg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Project Overview\n",
    "This project implements a deep learning solution for classifying chest X-ray images into:\n",
    "- Healthy vs Pneumonia (binary classification)\n",
    "- Normal vs Bacterial vs Viral Pneumonia (multi-class classification)\n",
    "\n",
    "The project uses convolutional neural networks (CNNs) to analyze X-ray images and provide accurate pneumonia detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Analysis and Exploration\n",
    "From the data exploration notebook (data_exploration.ipynb), we can see important dataset characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Distribution:\n",
    "- Training set:\n",
    "  - Normal: 1341 images\n",
    "  - Bacterial: 2530 images\n",
    "  - Viral: 1345 images\n",
    "- Test set:\n",
    "  - Normal: 234 images\n",
    "  - Bacterial: 242 images\n",
    "  - Viral: [number] images\n",
    "\n",
    "### Image Characteristics:\n",
    "- Most images are grayscale (5573 out of 5856)\n",
    "- Mean pixel intensity: 122.79\n",
    "- Standard deviation: 18.39\n",
    "- Only 2 anomalous images identified with unusual brightness levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Project Structure\n",
    "The project follows a well-organized structure as defined in the README.md:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PneumoScope/\n",
    "│\n",
    "├── data/                  # Folder for datasets\n",
    "│   ├── train/             # Training images\n",
    "│   ├── test/              # Testing images\n",
    "│   └── val/               # Validation images (optional)\n",
    "│\n",
    "├── notebooks/             # Jupyter notebooks for experiments and EDA\n",
    "│   ├── data_exploration.ipynb\n",
    "│   └── model_training.ipynb\n",
    "│\n",
    "├── src/                   # Source code\n",
    "│   ├── data_loader.py     # Code to load and preprocess the dataset\n",
    "│   ├── model.py           # Code to define the model architecture\n",
    "│   ├── train.py           # Script to train the model\n",
    "│   ├── evaluate.py        # Script to evaluate the model\n",
    "│   └── utils.py           # Helper functions\n",
    "│\n",
    "├── saved_models/          # Folder to save trained models\n",
    "│   ├── best_model.h5\n",
    "│   └── latest_model.h5\n",
    "│\n",
    "├── results/               # Folder for storing results and logs\n",
    "│   ├── plots/             # Training/validation curves, confusion matrices\n",
    "│   └── logs/              # Training logs\n",
    "│\n",
    "├── main.py                # Main script, runs training and evaluation\n",
    "├── requirements.txt       # List of dependencies\n",
    "├── reorganize_dataset.py  # Resizes train|val|test sizes\n",
    "├── README.md              # Project description and instructions\n",
    "├── .gitignore             # Ignored files/folders\n",
    "└── LICENSE                # License for the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Implementation Steps\n",
    "Based on the ToDo.md file, the project was implemented in several phases:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Preparation**\n",
    "- [X] Download the dataset from Kaggle. # Sebbe data_loader.py\n",
    "- [X] Organize the dataset into appropriate directories (`train`, `test`, `val`).\n",
    "- [X] Explore the dataset (e.g., check for class imbalance, image size). # Julia data_exploration.ipynb\n",
    "- [X] Perform data preprocessing: \n",
    "  - [X] Resize images to a uniform size.\n",
    "  - [X] Normalize image pixel values.\n",
    "  - [X] Apply data augmentation (e.g., flipping, rotation, zoom).\n",
    "\n",
    "## **3. Model Development**\n",
    "- [X] Choose baseline CNN architecture (e.g., simple CNN). # Ali\n",
    "- [X] Train a binary classification model (pneumonia vs. no pneumonia).\n",
    "- [X] Train a ternary classification model (bacterial vs. viral vs. no pneumonia). # Ali\n",
    "- [X] Experiment with pre-trained models (e.g., ResNet, VGG, Inception).\n",
    "- [X] Implement transfer learning if using pre-trained models.\n",
    "\n",
    "## **4. Model Evaluation** # Ali och Julia\n",
    "- [X] Evaluate models on the test set.\n",
    "- [X] Compute key metrics:\n",
    "  - [X] Accuracy\n",
    "  - [X] Precision, Recall, F1-score, Accuracy\n",
    "  - [X] ROC-AUC # Ali\n",
    "- [X] Create and display confusion matrices. # Julia\n",
    "- [X] Save model performance results for comparison. # Ali\n",
    "\n",
    "## **5. Optimization** # Sebastian\n",
    "- [X] Fine-tune hyperparameters (learning rate, batch size, number of epochs). \n",
    "- [X] Implement early stopping and learning rate scheduling. # Early stopping check, learning rate scheduler not yet implemented\n",
    "- [ ] Test different optimizers (e.g., Adam, SGD).\n",
    "- [X] Experiment with different data augmentation strategies. # Implemented but not tested\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main.py\n",
    "This file orchestrates the complete machine learning pipeline for pneumonia detection from X-ray images, both binary and multiclass classification tasks.\n",
    "### Pipeline Steps\n",
    "\n",
    "def main():\n",
    "\n",
    "Main pipeline:\n",
    "1) **Data Download**: Download data from Kaggle if not present\n",
    "2) **Data Reorganization**: Reorganize data for binary/multiclass if needed\n",
    "3) **Binary Classification**: Train and evaluate binary classifier\n",
    "4) **Multiclass Classification**: Train and evaluate multiclass classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Features\n",
    "1. **Automatic Data Management**\n",
    "   - Downloads dataset if missing\n",
    "   - Organizes data for both classification tasks\n",
    "\n",
    "2. **Binary Classification**\n",
    "   - Trains model (pneumonia vs. normal)\n",
    "   - Evaluates performance metrics\n",
    "   - Saves model and results\n",
    "\n",
    "3. **Multiclass Classification**\n",
    "   - Trains model (normal vs. bacterial vs. viral)\n",
    "   - Evaluates performance metrics\n",
    "   - Saves model and results\n",
    "\n",
    "### Output Metrics\n",
    "- Binary: Precision, Recall, F1, Accuracy, AUC\n",
    "- Multiclass: Macro-averaged metrics (Precision, Recall, F1) and Accuracy\n",
    "\n",
    "### Usage\n",
    "Run `python main.py` to execute the complete pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Application \n",
    "\n",
    "## app.py\n",
    "A Flask web application that serves a pneumonia detection model through a user interface.\n",
    "\n",
    "\n",
    "### Key Features\n",
    "1. **Model Setup**\n",
    "   - Loads pre-trained PneumoNet model\n",
    "   - Configures for CPU/GPU automatically\n",
    "   - Handles image preprocessing\n",
    "\n",
    "2. **Routes**\n",
    "   - `/`: Home page with upload interface\n",
    "   - `/predict`: Handles image processing and prediction\n",
    "\n",
    "3. **Prediction Pipeline**\n",
    "   - Accepts uploaded X-ray images\n",
    "   - Preprocesses images to model requirements\n",
    "   - Returns binary classification (Normal/Pneumonia)\n",
    "\n",
    "### Usage\n",
    "1. Run `python app.py`\n",
    "2. Open browser to `http://localhost:5000`\n",
    "3. Upload X-ray image for prediction\n",
    "\n",
    "### Security Features\n",
    "- Temporary file handling\n",
    "- Input validation\n",
    "- Automatic file cleanup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading \n",
    "\n",
    "## data_loader.py\n",
    "Handles data loading and preprocessing for the pneumonia detection model, including data augmentation and class balancing.\n",
    "\n",
    "### Key Components\n",
    "def get_data_loaders(data_dir, batch_size, num_workers, augment_train, random_crop,\n",
    "color_jitter, balance_train, desired_total_samples, multiclass=False):\n",
    "\n",
    "Creates DataLoaders for training, validation, and testing\n",
    "with configurable augmentation and balancing options.\n",
    "\n",
    "### Features\n",
    "1. **Data Transforms**\n",
    "   - Resizing (224x224 or 256→224 with random crop)\n",
    "   - Augmentations: horizontal flip, rotation, color jitter\n",
    "   - Normalization using ImageNet statistics\n",
    "\n",
    "2. **Data Loading**\n",
    "   - Separate loaders for train/val/test\n",
    "   - Class verification against expected labels\n",
    "   - Support for both binary and multiclass\n",
    "\n",
    "3. **Class Balancing**\n",
    "   - Optional weighted sampling for imbalanced datasets\n",
    "   - Configurable total samples\n",
    "   - Uses `WeightedRandomSampler`\n",
    "\n",
    "### Parameters\n",
    "- `data_dir`: Dataset root directory\n",
    "- `batch_size`: Samples per batch\n",
    "- `augment_train`: Enable training augmentations\n",
    "- `balance_train`: Enable class balancing\n",
    "- `multiclass`: Toggle binary/multiclass mode\n",
    "\n",
    "### Returns\n",
    "Three DataLoaders: training, validation, and testing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Evaluation\n",
    "\n",
    "## evaluate_multiclass.py\n",
    "Evaluates the performance of the multiclass pneumonia detection model (Normal vs. Bacterial vs. Viral).\n",
    "\n",
    "### Key Components\n",
    "def evaluate_model_multiclass(model_path, data_dir, results_dir='results/multiclass'):\n",
    "\n",
    "Evaluates trained model on test dataset and calculates performance metrics.\n",
    "\n",
    "### Features\n",
    "\n",
    "1. **Model Evaluation**\n",
    "   - Loads trained model from checkpoint\n",
    "   - Processes test dataset\n",
    "   - Calculates comprehensive metrics\n",
    "\n",
    "2. **Performance Metrics**\n",
    "   - Confusion matrix\n",
    "   - Macro-averaged metrics (class-independent)\n",
    "   - Micro-averaged metrics (class-size aware)\n",
    "   - Per-class performance analysis\n",
    "\n",
    "3. **Results Storage**\n",
    "   - Saves metrics as JSON\n",
    "   - Includes detailed per-class analysis\n",
    "   - Stores confusion matrix\n",
    "\n",
    "### Key Metrics\n",
    "- Precision (macro/micro)\n",
    "- Recall (macro/micro)\n",
    "- F1-score (macro/micro)\n",
    "- Accuracy\n",
    "- Per-class performance\n",
    "\n",
    "### Output\n",
    "- Console output with detailed metrics\n",
    "- JSON file with complete evaluation results\n",
    "- Confusion matrix visualization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Evaluation\n",
    "\n",
    "## evaluate.py\n",
    "Evaluates the performance of the binary pneumonia detection model (Normal vs. Pneumonia).\n",
    "\n",
    "### Key Components\n",
    "def evaluate_model(model_path, data_dir, results_dir='results', plot_cm=False):\n",
    "\n",
    "Evaluates trained model on test dataset and generates comprehensive metrics.\n",
    "\n",
    "\n",
    "### Features\n",
    "1. **Model Evaluation**\n",
    "   - Loads PneumoNet model from checkpoint\n",
    "   - Uses standardized test data loader\n",
    "   - No augmentation during evaluation\n",
    "\n",
    "2. **Performance Metrics**\n",
    "   - Binary classification metrics\n",
    "   - ROC and PR curves analysis\n",
    "   - Detailed per-class statistics\n",
    "\n",
    "3. **Results Management**\n",
    "   - JSON output with all metrics\n",
    "   - Model information tracking\n",
    "   - Checkpoint metadata storage\n",
    "\n",
    "### Key Metrics\n",
    "- Precision & Recall\n",
    "- F1-score\n",
    "- Accuracy\n",
    "- ROC-AUC score\n",
    "- PR-AUC\n",
    "- Average Precision\n",
    "- Per-class metrics\n",
    "\n",
    "### Parameters\n",
    "- `model_path`: Path to model checkpoint\n",
    "- `data_dir`: Dataset location\n",
    "- `results_dir`: Output directory\n",
    "- `plot_cm`: Confusion matrix plotting flag\n",
    "\n",
    "### Output\n",
    "- Console summary of results\n",
    "- Detailed JSON metrics file\n",
    "- Model evaluation statistics\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "## hyperparameter_tuning.py\n",
    "\n",
    "### Key Components\n",
    "def grid_search(data_dir):\n",
    "\n",
    "Performs exhaustive grid search over specified hyperparameter ranges.\n",
    "\n",
    "\n",
    "### Features\n",
    "1. **Grid Search**\n",
    "   - Exhaustive search over parameter combinations\n",
    "   - Tracks best performing parameters\n",
    "   - Stores all trial results\n",
    "\n",
    "2. **Parameters Tuned**\n",
    "   - Learning rate\n",
    "   - Batch size\n",
    "   - Number of epochs\n",
    "   - Early stopping patience\n",
    "   - Learning rate scheduler settings\n",
    "\n",
    "3. **Results Tracking**\n",
    "   - Best validation accuracy\n",
    "   - Parameter combination history\n",
    "   - Performance metrics per trial\n",
    "\n",
    "### Returns\n",
    "- Best parameters found\n",
    "- Complete results history\n",
    "- Validation accuracy for each combination\n",
    "\n",
    "### Usage\n",
    "Used to optimize model training parameters before final training run.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Dataset Downloader\n",
    "\n",
    "## kaggle_downloader.py\n",
    "Handles automated download and extraction of the chest X-ray pneumonia dataset from Kaggle.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "def download_dataset_if_needed():\n",
    "\n",
    "Downloads and organizes the chest X-ray dataset:\n",
    "- Downloads from Kaggle if not present\n",
    "- Extracts ZIP to downloads folder\n",
    "- Moves train/val/test to data folder\n",
    "- Cleans up temporary files\n",
    "\n",
    "### Features\n",
    "1. **Dataset Management**\n",
    "   - Automatic Kaggle dataset download\n",
    "   - Handles ZIP extraction\n",
    "   - Organizes into train/val/test splits\n",
    "\n",
    "2. **Directory Structure**\n",
    "   - Creates necessary folders\n",
    "   - Maintains clean project structure\n",
    "   - Removes temporary files\n",
    "\n",
    "3. **Error Handling**\n",
    "   - Checks for existing data\n",
    "   - Validates downloaded files\n",
    "   - Ensures proper cleanup\n",
    "\n",
    "### Requirements\n",
    "- Kaggle API credentials\n",
    "- `kaggle` Python package\n",
    "- Sufficient disk space\n",
    "\n",
    "### Output\n",
    "Organized dataset in `data/` with:\n",
    "- train/\n",
    "- val/\n",
    "- test/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "## model.py\n",
    "Defines the PneumoNet model architecture using a pre-trained ResNet18 backbone for pneumonia detection.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "class PneumoNet(nn.Module):\n",
    "\n",
    "Neural network for pneumonia detection:\n",
    "- Based on ResNet18 architecture\n",
    "- Configurable for binary/multiclass\n",
    "- Optional pre-trained weights\n",
    "\n",
    "\n",
    "def init(self, num_classes=1, use_pretrained=True):\n",
    "- Initialize with ImageNet weights or from scratch\n",
    "- Modifies final layer for classification task\n",
    "\n",
    "\n",
    "### Features\n",
    "1. **Model Architecture**\n",
    "   - ResNet18 backbone\n",
    "   - Modified final layer for classification\n",
    "   - ImageNet pre-trained weights option\n",
    "\n",
    "2. **Configuration Options**\n",
    "   - Binary classification (num_classes=1)\n",
    "   - Multiclass support (num_classes>1)\n",
    "   - Flexible pre-training toggle\n",
    "\n",
    "3. **Implementation Details**\n",
    "   - Inherits from nn.Module\n",
    "   - Uses modern weights parameter\n",
    "   - Maintains ResNet architecture benefits\n",
    "\n",
    "### Parameters\n",
    "- `num_classes`: Output classes (1 for binary)\n",
    "- `use_pretrained`: Toggle ImageNet weights\n",
    "\n",
    "### Usage\n",
    "Core model used in both training and inference pipelines\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Reorganization\n",
    "\n",
    "## reorganize_dataset.py\n",
    "Handles dataset reorganization for both binary(Normal/Pneumonia) and multiclass(Normal/Bacterial/Viral) classification.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "def reorganize_dataset(data_dir=\"data\", val_size=0.15, test_size=0.15):\n",
    "\n",
    "Reorganizes chest X-ray dataset into two formats:\n",
    "- Binary: data/ (NORMAL vs PNEUMONIA)\n",
    "- Multiclass: data_multi/ (NORMAL vs BACTERIA vs VIRUS)\n",
    "\n",
    "### Features\n",
    "1. **Data Organization**\n",
    "   - Creates binary classification structure\n",
    "   - Creates multiclass classification structure\n",
    "   - Maintains data splits (train/val/test)\n",
    "\n",
    "2. **File Management**\n",
    "   - Extracts pneumonia type from filenames\n",
    "   - Handles file copying and moving\n",
    "   - Maintains data integrity\n",
    "\n",
    "3. **Split Configuration**\n",
    "   - Configurable validation split\n",
    "   - Configurable test split\n",
    "   - Random shuffling of data\n",
    "\n",
    "\n",
    "### Statistics\n",
    "- Prints dataset distribution\n",
    "- Shows class balance information\n",
    "- Reports total images per category\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Training\n",
    "\n",
    "## train_multiclass.py\n",
    "Implements training pipeline for three-class pneumonia classification (Normal vs. Bacterial vs. Viral).\n",
    "\n",
    "### Key Components\n",
    "\n",
    "class PneumoNetMulti(nn.Module):\n",
    "\n",
    "Multi-class variant of PneumoNet:\n",
    "- ResNet18 backbone\n",
    "- 3-class output layer\n",
    "- ImageNet pre-training option\n",
    "\n",
    "def train_model_multiclass(data_dir, save_dir=None, results_dir=None):\n",
    "\n",
    "Main training function with:\n",
    "- Automatic mixed precision\n",
    "- Early stopping\n",
    "- Model checkpointing\n",
    "\n",
    "\n",
    "### Features\n",
    "1. **Training Pipeline**\n",
    "   - Mixed precision training\n",
    "   - Early stopping mechanism\n",
    "   - Learning rate scheduling\n",
    "   - Model checkpointing\n",
    "\n",
    "2. **Hyperparameters**\n",
    "   - Epochs: 50\n",
    "   - Learning rate: 0.001\n",
    "   - Batch size: 32\n",
    "   - Early stopping patience: 10\n",
    "   - Data augmentation options\n",
    "\n",
    "3. **Metrics Tracking**\n",
    "   - Loss (train/val)\n",
    "   - Accuracy (train/val)\n",
    "   - F1-score (train/val)\n",
    "   - Precision/Recall\n",
    "   - Confusion matrices\n",
    "\n",
    "### Output\n",
    "- Best model checkpoint\n",
    "- Training history\n",
    "- Performance metrics\n",
    "- Confusion matrices\n",
    "\n",
    "### Returns\n",
    "- Trained model\n",
    "- Best checkpoint path\n",
    "- Training logs path\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Training\n",
    "\n",
    "## train.py\n",
    "Implements the main training pipeline for binary pneumonia classification (Normal vs. Pneumonia).\n",
    "\n",
    "### Key Components\n",
    "\n",
    "def train_model(data_dir, save_dir=None, results_dir=None):\n",
    "\n",
    "Main training function with:\n",
    "- Automatic mixed precision (AMP)\n",
    "- Early stopping\n",
    "- Comprehensive metrics tracking\n",
    "\n",
    "\n",
    "### Features\n",
    "1. **Training Pipeline**\n",
    "   - GPU/CPU support with AMP\n",
    "   - Early stopping\n",
    "   - Model checkpointing\n",
    "   - Comprehensive logging\n",
    "\n",
    "2. **Key Functions**\n",
    "   - `train_epoch`: Single epoch training/validation\n",
    "   - `train_model`: Complete training pipeline\n",
    "   - Metrics calculation and logging\n",
    "\n",
    "3. **Metrics Tracked**\n",
    "   - Loss (train/val)\n",
    "   - Precision/Recall\n",
    "   - F1-score\n",
    "   - Accuracy\n",
    "   - AUC-ROC\n",
    "   - Confusion matrices\n",
    "\n",
    "### Output\n",
    "- Model checkpoints\n",
    "- Training history (JSON)\n",
    "- Performance metrics\n",
    "- Confusion matrices\n",
    "\n",
    "### Returns\n",
    "- Trained model\n",
    "- Best model path\n",
    "- Training logs path\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities \n",
    "\n",
    "## utils.py\n",
    "Contains utility functions and constants used in the project.\n",
    "\n",
    "\n",
    "### Features\n",
    "1. **Constants**\n",
    "   - Class names for binary classification\n",
    "   - Class names for multiclass classification\n",
    "   - Matches filesystem organization\n",
    "\n",
    "2. **GPU Utilities**\n",
    "   - GPU availability check\n",
    "   - Memory usage tracking\n",
    "   - Device allocation info\n",
    "\n",
    "3. **Checkpoint Management**\n",
    "   - Model state saving\n",
    "   - Optimizer state saving\n",
    "   - Training metrics storage\n",
    "   - Directory creation handling\n",
    "\n",
    "### Usage\n",
    "- Import class names for consistency\n",
    "- Monitor GPU resources\n",
    "- Save training progress\n",
    "- Load model checkpoints\n",
    "\n",
    "### Returns\n",
    "- GPU statistics to console\n",
    "- Checkpoint paths when saving\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebooks**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "\n",
    "## Analysis_of_models.ipynb\n",
    "Jupyter notebook for analyzing and visualizing model performance after training.\n",
    "\n",
    "### Key Components\n",
    "**Main analysis sections**:\n",
    "- Plot training/validation metrics\n",
    "- Visualize model predictions\n",
    "- Generate Grad-CAM visualizations\n",
    "\n",
    "\n",
    "### Features\n",
    "1. **Performance Visualization**\n",
    "   - Training/validation loss curves\n",
    "   - Accuracy, precision, recall plots\n",
    "   - F1-score tracking\n",
    "   - AUC-ROC curves\n",
    "\n",
    "2. **Confusion Matrices**\n",
    "   - Last three epochs analysis\n",
    "   - Side-by-side train/val comparison\n",
    "   - Class-wise performance\n",
    "\n",
    "3. **Model Interpretation**\n",
    "   - Grad-CAM heatmaps\n",
    "   - Correct vs incorrect predictions\n",
    "   - Attention visualization\n",
    "\n",
    "### Key Plots\n",
    "- Loss curves\n",
    "- Metric curves (5 metrics)\n",
    "- Confusion matrices\n",
    "- Grad-CAM visualizations\n",
    "\n",
    "### Dependencies\n",
    "- torch\n",
    "- matplotlib\n",
    "- numpy\n",
    "- PIL\n",
    "- torchvision\n",
    "\n",
    "### Usage\n",
    "Run cells sequentially to:\n",
    "1. Load training logs\n",
    "2. Generate performance plots\n",
    "3. Analyze model behavior\n",
    "4. Visualize model attention\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "## data_exploration.ipynb\n",
    "\n",
    "### Key Components\n",
    "\n",
    "**Main exploration sections**:\n",
    "- Dataset distribution analysis\n",
    "- Image visualization\n",
    "- Quality checks\n",
    "\n",
    "### Features\n",
    "1. **Dataset Statistics**\n",
    "   - Distribution by class (normal/pneumonia)\n",
    "   - Distribution by type (bacterial/viral)\n",
    "   - Split ratios (train/val/test)\n",
    "   - Class balance analysis\n",
    "\n",
    "2. **Image Analysis**\n",
    "   - Sample image visualization\n",
    "   - Image size distribution\n",
    "   - Grayscale vs color check\n",
    "   - Brightness/contrast analysis\n",
    "\n",
    "3. **Quality Checks**\n",
    "   - Small file detection\n",
    "   - Corrupted image check\n",
    "   - Anomalous brightness detection\n",
    "   - Image statistics (mean/std)\n",
    "\n",
    "### Key Visualizations\n",
    "- Bar charts of class distribution\n",
    "- Sample images from each category\n",
    "- Brightness distribution plots\n",
    "- Image size histograms\n",
    "\n",
    "### Dependencies\n",
    "- pandas\n",
    "- matplotlib\n",
    "- PIL\n",
    "- numpy\n",
    "\n",
    "### Key Findings\n",
    "- Dataset imbalance details\n",
    "- Image quality metrics\n",
    "- Potential preprocessing needs\n",
    "- Anomaly detection results\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
